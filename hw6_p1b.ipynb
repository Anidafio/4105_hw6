{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5sGrjdl0ISVy6HItN4/uF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anidafio/4105_hw6/blob/main/hw6_p1b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rm3omIXITFcl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "url = 'https://raw.githubusercontent.com/Anidafio/4105_hw6/main/Housing.csv'\n",
        "\n",
        "housing = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "varlist =  ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
        "\n",
        "def binary_map(x):\n",
        "    return x.map({'yes': 1, 'no': 0})\n",
        "\n",
        "housing[varlist] = housing[varlist].apply(binary_map)\n",
        "\n",
        "variables =  ['area', 'bedrooms', 'bathrooms', 'stories', 'mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea', 'parking']\n",
        "\n",
        "X = housing[variables].copy().values\n",
        "Y = housing[['price']].copy().values\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "nc_X = MinMaxScaler()\n",
        "X = nc_X.fit_transform(X)\n",
        "Y = nc_X.fit_transform(Y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 100)"
      ],
      "metadata": {
        "id": "LUnuKjWZJlfN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "X_train = torch.tensor(X_train)\n",
        "Y_train = torch.tensor(Y_train)\n",
        "X_test = torch.tensor(X_test)\n",
        "Y_test = torch.tensor(Y_test)"
      ],
      "metadata": {
        "id": "kSbgwfRGc-Rt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val,\n",
        "                  t_c_train, t_c_val):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        t_p_train = model(t_u_train) # <1>\n",
        "        loss_train = loss_fn(t_p_train, t_c_train)\n",
        "\n",
        "        t_p_val = model(t_u_val) # <1>\n",
        "        loss_val = loss_fn(t_p_val, t_c_val)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_train.backward() # <2>\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch == 1 or epoch % 1000 == 0:\n",
        "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
        "                  f\" Validation loss {loss_val.item():.4f}\")"
      ],
      "metadata": {
        "id": "47l7KgSkeaOM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HScvaOLAfhCC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "seq_model = nn.Sequential(\n",
        "            nn.Linear(11, 32, dtype=torch.float64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(32, 64, dtype=torch.float64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(64, 16, dtype=torch.float64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(16, 1, dtype=torch.float64))\n",
        "seq_model\n",
        "\n",
        "optimizer = optim.SGD(seq_model.parameters(), lr=1e-3) # <1>\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 10000,\n",
        "    optimizer = optimizer,\n",
        "    model = seq_model,\n",
        "    loss_fn = nn.MSELoss(),\n",
        "    t_u_train = X_train,\n",
        "    t_u_val = X_test,\n",
        "    t_c_train = Y_train,\n",
        "    t_c_val = Y_test)\n",
        "\n",
        "#print('output', seq_model(X_test))\n",
        "#print('answer', Y_test)\n",
        "#print('hidden', seq_model.hidden_linear.weight.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgGzSCwkKE2a",
        "outputId": "57ce1e92-bb2b-4f09-ae58-485dc1347dfd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 0.0486, Validation loss 0.0468\n",
            "Epoch 1000, Training loss 0.0238, Validation loss 0.0257\n",
            "Epoch 2000, Training loss 0.0212, Validation loss 0.0225\n",
            "Epoch 3000, Training loss 0.0192, Validation loss 0.0200\n",
            "Epoch 4000, Training loss 0.0176, Validation loss 0.0181\n",
            "Epoch 5000, Training loss 0.0163, Validation loss 0.0165\n",
            "Epoch 6000, Training loss 0.0152, Validation loss 0.0153\n",
            "Epoch 7000, Training loss 0.0143, Validation loss 0.0143\n",
            "Epoch 8000, Training loss 0.0135, Validation loss 0.0134\n",
            "Epoch 9000, Training loss 0.0129, Validation loss 0.0127\n",
            "Epoch 10000, Training loss 0.0124, Validation loss 0.0122\n"
          ]
        }
      ]
    }
  ]
}