{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNiXp+hDOeAwmONUGm45NKe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anidafio/4105_hw6/blob/main/hw6_p2a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWgkc9WHw9zw",
        "outputId": "90fcee53-2280-4712-a149-f6f406dec7ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12866776.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                             (0.5, 0.5, 0.5))\n",
        "    ]))\n",
        "\n",
        "cifar10_val = datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                             (0.5, 0.5, 0.5))\n",
        "    ]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "seq_model = nn.Sequential(\n",
        "            nn.Linear(3072, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1))\n",
        "\n",
        "optimizer = optim.SGD(seq_model.parameters(), lr=1e-3) # <1>\n",
        "\n",
        "loss_fn = nn.NLLLoss()\n",
        "n_epochs = 100\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        outputs = seq_model(imgs.view(imgs.shape[0], -1))\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD58A7Acz1fu",
        "outputId": "e460411c-cdbe-4b51-9394-d73f1ccd851c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 2.126782\n",
            "Epoch: 1, Loss: 1.950603\n",
            "Epoch: 2, Loss: 2.285083\n",
            "Epoch: 3, Loss: 1.960138\n",
            "Epoch: 4, Loss: 1.859585\n",
            "Epoch: 5, Loss: 1.179471\n",
            "Epoch: 6, Loss: 1.320779\n",
            "Epoch: 7, Loss: 2.114601\n",
            "Epoch: 8, Loss: 1.793222\n",
            "Epoch: 9, Loss: 1.676662\n",
            "Epoch: 10, Loss: 1.798662\n",
            "Epoch: 11, Loss: 1.346051\n",
            "Epoch: 12, Loss: 1.660064\n",
            "Epoch: 13, Loss: 1.479390\n",
            "Epoch: 14, Loss: 1.885503\n",
            "Epoch: 15, Loss: 1.456050\n",
            "Epoch: 16, Loss: 2.021192\n",
            "Epoch: 17, Loss: 1.733462\n",
            "Epoch: 18, Loss: 1.613314\n",
            "Epoch: 19, Loss: 1.592013\n",
            "Epoch: 20, Loss: 1.413223\n",
            "Epoch: 21, Loss: 2.089406\n",
            "Epoch: 22, Loss: 1.466303\n",
            "Epoch: 23, Loss: 1.519690\n",
            "Epoch: 24, Loss: 1.872882\n",
            "Epoch: 25, Loss: 2.096097\n",
            "Epoch: 26, Loss: 1.650347\n",
            "Epoch: 27, Loss: 1.519679\n",
            "Epoch: 28, Loss: 1.732410\n",
            "Epoch: 29, Loss: 1.806820\n",
            "Epoch: 30, Loss: 1.825547\n",
            "Epoch: 31, Loss: 1.508922\n",
            "Epoch: 32, Loss: 1.732424\n",
            "Epoch: 33, Loss: 1.765575\n",
            "Epoch: 34, Loss: 1.504339\n",
            "Epoch: 35, Loss: 1.836615\n",
            "Epoch: 36, Loss: 1.576985\n",
            "Epoch: 37, Loss: 1.454560\n",
            "Epoch: 38, Loss: 1.653649\n",
            "Epoch: 39, Loss: 1.696110\n",
            "Epoch: 40, Loss: 1.571579\n",
            "Epoch: 41, Loss: 1.735502\n",
            "Epoch: 42, Loss: 1.653501\n",
            "Epoch: 43, Loss: 1.822862\n",
            "Epoch: 44, Loss: 1.684956\n",
            "Epoch: 45, Loss: 1.466085\n",
            "Epoch: 46, Loss: 2.108194\n",
            "Epoch: 47, Loss: 1.537233\n",
            "Epoch: 48, Loss: 1.451570\n",
            "Epoch: 49, Loss: 1.484126\n",
            "Epoch: 50, Loss: 1.472790\n",
            "Epoch: 51, Loss: 1.402056\n",
            "Epoch: 52, Loss: 2.002561\n",
            "Epoch: 53, Loss: 1.577982\n",
            "Epoch: 54, Loss: 1.474370\n",
            "Epoch: 55, Loss: 1.951831\n",
            "Epoch: 56, Loss: 1.375967\n",
            "Epoch: 57, Loss: 1.136433\n",
            "Epoch: 58, Loss: 1.454373\n",
            "Epoch: 59, Loss: 1.099218\n",
            "Epoch: 60, Loss: 1.428223\n",
            "Epoch: 61, Loss: 1.544274\n",
            "Epoch: 62, Loss: 1.521039\n",
            "Epoch: 63, Loss: 1.763794\n",
            "Epoch: 64, Loss: 1.701336\n",
            "Epoch: 65, Loss: 1.710724\n",
            "Epoch: 66, Loss: 1.544430\n",
            "Epoch: 67, Loss: 1.101218\n",
            "Epoch: 68, Loss: 1.514906\n",
            "Epoch: 69, Loss: 1.566961\n",
            "Epoch: 70, Loss: 1.738806\n",
            "Epoch: 71, Loss: 1.781670\n",
            "Epoch: 72, Loss: 1.694180\n",
            "Epoch: 73, Loss: 1.381720\n",
            "Epoch: 74, Loss: 1.408349\n",
            "Epoch: 75, Loss: 1.397437\n",
            "Epoch: 76, Loss: 1.772193\n",
            "Epoch: 77, Loss: 0.937875\n",
            "Epoch: 78, Loss: 1.585870\n",
            "Epoch: 79, Loss: 1.343461\n",
            "Epoch: 80, Loss: 1.690873\n",
            "Epoch: 81, Loss: 1.669016\n",
            "Epoch: 82, Loss: 1.354908\n",
            "Epoch: 83, Loss: 2.052393\n",
            "Epoch: 84, Loss: 1.705908\n",
            "Epoch: 85, Loss: 1.314614\n",
            "Epoch: 86, Loss: 1.509762\n",
            "Epoch: 87, Loss: 1.615229\n",
            "Epoch: 88, Loss: 1.657971\n",
            "Epoch: 89, Loss: 1.833624\n",
            "Epoch: 90, Loss: 1.396505\n",
            "Epoch: 91, Loss: 1.535309\n",
            "Epoch: 92, Loss: 1.471725\n",
            "Epoch: 93, Loss: 1.671146\n",
            "Epoch: 94, Loss: 1.530607\n",
            "Epoch: 95, Loss: 1.636444\n",
            "Epoch: 96, Loss: 1.624191\n",
            "Epoch: 97, Loss: 1.265612\n",
            "Epoch: 98, Loss: 1.514422\n",
            "Epoch: 99, Loss: 1.717431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in train_loader:\n",
        "        outputs = seq_model(imgs.view(imgs.shape[0], -1))\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "\n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr-ATDyAgeqb",
        "outputId": "5f9a7d08-d6f2-45d6-b2f6-5f989d905c06"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.490180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        outputs = seq_model(imgs.view(imgs.shape[0], -1))\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "\n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ18mbiLgzZR",
        "outputId": "1ad59696-927b-45dc-9587-6ccec669c8ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.458200\n"
          ]
        }
      ]
    }
  ]
}